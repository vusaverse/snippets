snippet intro
	## +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	## R code for Education Analytics Vrije Universiteit Amsterdam
	## Copyright `r format(Sys.Date(), "%Y")` VU
	## Web Page: http://www.vu.nl
	## Contact: `r Sys.getenv("TEAM_EMAIL")`
	##
	##' *INFO*:
	## 1) ___
	##
	## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

snippet standard_as
	vColumns <- c(
		"INS_Faculteit",
		"INS_Inschrijvingsjaar",
		"INS_Inschrijvingsjaar_EOI",
		"INS_Opleidingsfase_BPM",
		"INS_Opleidingsnaam_2002",
		"INS_Studentnummer",
		"INS_Studiejaar",
		"INS_Hoofdneven",
		"INS_Indicatie_actief_op_peildatum_status"
	)
	${0}
	dfAS <- get_analysisset(columns = vColumns)

snippet standard_res_as
	vColumns <- c(
	"INS_Studentnummer",
	"INS_Opleidingsnaam_2002",
	"RES_Beoordeling",
	"RES_EC_numeriek_geboekt",
	"RES_Inschrijving_soort",
	"RES_Poging_nummer"
	)
	${0}
	dfRESAS <- vusa::get_analysisset_res(columns=vColumns)

snippet standard_vak_as
	vColumns <- c(
	"UAS_Vak_Jaar",
	"UAS_Vak_Code",
	"UAS_Vak_Naam_NL",
	"UAS_Vak_Vaktype"
	)
	${0}
	dfVAKAS <- vusa::get_analysisset_vak(columns=vColumns)

snippet standard_opl_as
	vColumns <- c(
	"INS_Opleidingsnaam_2002",
	"INS_Inschrijvingsjaar",
	"UAS_Opleiding_Code",
	"UAS_Opleiding_Naam_NL"
	)
	${0}
	dfOPLAS <- vusa::get_analysisset_opl(columns=vColumns)

snippet etl_workflow
	# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	#                              ETL Workflow for ${1:PIPELINE}
	# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

	# ------------------------------ 0. Configurations -----------------------------
	## TODO: change pathnames to fit the pipeline
	dataset <- .config$datasets$${1}
	RAW_DATA_PATH <- file.path(Sys.getenv("RAW_DATA_PATH"), dataset$paths$dir)
	FILE_PATTERN <- dataset$paths$file_pattern
	DATASET_NAME <- dataset$naming$dataset_name

	## TODO: change the source to the right utility functions
	# Load data specific utility functions
	# example: source("01_ETL/BSA/BSA_helpers.R")
	source("01_ETL/${1}/${1}_helpers.R")

	# --------------------------- 1. Raw Data Ingestion ----------------------------
	file_path <- vvmover::get_recent_file_date_filename_ymd(
		RAW_DATA_PATH,
		FILE_PATTERN
	)

	df${1}_RAW <- tryCatch(
		{
			## TODO: add read helper function
			# example: read_bsa(file_path)
		},
		error = function(e) {
			stop(paste("Error reading raw data:", e$message))
		}
	)

	## TODO: change export function to adhere to pipeline
	etl_export(
		data = df${1}_RAW,
		dataset_name = paste0(DATASET_NAME, "_raw")
		# step = "raw"
	)

	# ------------------------- 2. Clean & Basic Transformations -------------------
	# Allowed transformations in this step:
	# Renaming of columns: rename, setNames
	# Type changing: as.x
	# Keeping distinct values: distinct

	## Renaming ##
	df${1}_CLEANED <- dfBSA_RAW %>%
		# Change column names to preferred names
		apply_column_mapping(dataset)

	## Mutations ##
	df${1}_CLEANED <- df${1}_CLEANED %>%
		${2:mutate()}  # example transformation

	## TODO: change export function to adhere to pipeline
	etl_export(
		data = df${1}_CLEANED,
		dataset_name = paste0(DATASET_NAME, "_cleaned")
		# step = "cleaned"
	)

	# ----------------- 3. Apply Business Logic (Corrections & Enrichment) ---------
	# Perform Business logic transformations
	df${1}_ENRICHED <- df${1}_CLEANED %>%
		${3:mutate()}  # enrichment example

	etl_export(
		data = df${1}_ENRICHED,
		dataset_name = paste0(DATASET_NAME, "_enriched")
		# step = "enriched"
	)

	# ------------------------------- 4. Cleanup -----------------------------------
	vusa::clear_global_proj()

	${0}
